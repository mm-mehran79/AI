{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6973c7b3",
   "metadata": {},
   "source": [
    "# AI Fall 2022 - A4 - Decision Tree\n",
    "## Your info\n",
    "\n",
    "**Student Name:** Mehran Mazaheri\n",
    "\n",
    "**Student Id:** 98102346"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583aa5d3",
   "metadata": {},
   "source": [
    "## Practical Question - Decision Tree (25 + 5 points)\n",
    "In this question you will first write a program to find an appropriate order of features for training a decision tree based on information gain. In the second part, you will use existing implementations to train and tune a classifier using GridSearch on the given dataset. And try to finish this in <15 mins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5a6c8",
   "metadata": {},
   "source": [
    "### Import\n",
    "Import the libraries you need in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b6cef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log2\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcc062",
   "metadata": {},
   "source": [
    "### Part A (20 points)\n",
    "Consider the following dataframe and answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bfb62d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>25.803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>33.394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>32.918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race  Sex   Age     BMI  Smoker  Label\n",
       "0   1.0  1.0  43.0  25.803     1.0  False\n",
       "1   2.0  2.0  72.0  33.394     0.0   True\n",
       "2   1.0  2.0   4.0  20.278     1.0  False\n",
       "3   1.0  2.0  59.0  32.918     0.0  False\n",
       "4   1.0  2.0  34.0  30.743     1.0  False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Race': [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    'Sex': [1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0],\n",
    "    'Age': [43.0, 72.0, 4.0, 59.0, 34.0, 55.0, 41.0, 39.0, 6.0, 77.0, 67.0, 35.0, 45.0, 39.0, 32.0, 57.0, 99.0, 68.0, 47.0, 28.0],\n",
    "    'BMI': [25.803, 33.394, 20.278, 32.918, 30.743, 37.734, 23.725, 20.722, 19.452, 22.044, 17.481, 18.918, 28.578, 19.214, 23.562, 23.446, 21.872, 20.691, 25.471, 25.82],\n",
    "    'Smoker': [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    'Label': [False, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, True, False],\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdcfa1",
   "metadata": {},
   "source": [
    "#### QA.1 (10 points)\n",
    "Complete the following function that calculates and returns the list of features based on their information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1ca880b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(label: list) -> float:\n",
    "    seen = []\n",
    "    H = 0\n",
    "    numberOfSamples = len(label)\n",
    "    for value in label:\n",
    "        if value not in seen:\n",
    "            seen.append(value)\n",
    "            numberOfOccurrence = label.count(value)\n",
    "            if numberOfOccurrence < numberOfSamples:\n",
    "                H -= numberOfOccurrence/numberOfSamples * log2(numberOfOccurrence/numberOfSamples)\n",
    "    return H\n",
    "\n",
    "def conditionalEntropy(feature: list, label: list) -> float:\n",
    "    seen = []\n",
    "    numberOfSamples = len(feature)\n",
    "    H = 0\n",
    "    for value in feature: \n",
    "        if value not in seen:\n",
    "            seen.append(value)\n",
    "            indices = [i for i, e in enumerate(feature) if e == value]\n",
    "            numberOfValue = len(indices)\n",
    "            newLabel = [label[i] for i in indices]\n",
    "            H += (numberOfValue/numberOfSamples) * entropy(newLabel)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "376c215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gains:\n",
      " {'Age': 0.7219280948873623, 'BMI': 0.7219280948873623, 'Race': 0.03690791540384364, 'Smoker': 0.03051882909598158, 'Sex': 0.0018149273570102764}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Age', 'BMI', 'Race', 'Smoker', 'Sex']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_order(X_data:pd.DataFrame, y_data:pd.Series):\n",
    "    '''\n",
    "    Calculate the best feature order\n",
    "    for training a decision tree based on\n",
    "    information gain.\n",
    "    Input:\n",
    "        X_data (pd.DataFrame) contains data features\n",
    "        y_data (pd.Series) contains the labels\n",
    "    Output:\n",
    "        order (list[str]): The `X_data` columns in the correct order\n",
    "    '''\n",
    "    informationGain = {}\n",
    "    for col in X_data.columns:\n",
    "        informationGain[col] = entropy(list(y_data)) - conditionalEntropy(list(df.get(col)), list(y_data))\n",
    "    informationGain = dict(sorted(informationGain.items(), key=lambda item: -item[1]))\n",
    "    print(\"Information Gains:\\n\", informationGain)\n",
    "\n",
    "    order = list(informationGain.keys())\n",
    "    return order\n",
    "\n",
    "\n",
    "feature_order(df.get(df.columns[:-1]), df.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61bfeb",
   "metadata": {},
   "source": [
    "#### QA.2 (5 points)\n",
    "What are some of the effective approaches to prevent the tree from overfitting? (three approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960950b9",
   "metadata": {},
   "source": [
    "<font color=#183364>\n",
    "    <i>\n",
    "        Answer.\n",
    "        <ol>\n",
    "            <li></li>\n",
    "            <li></li>\n",
    "            <li></li>\n",
    "        </ol>\n",
    "    </i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02158721",
   "metadata": {},
   "source": [
    "#### QA.3 (5 points)\n",
    "About the `Age` feature which is an integer-valued input attribute, how can a tree utilize it for classification? Write a small piece of code to find the answer for this specific column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244b4fe",
   "metadata": {},
   "source": [
    "<font color=#183364>\n",
    "    <i>\n",
    "        Answer.\n",
    "    </i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad880d0",
   "metadata": {},
   "source": [
    "### Part B (10 points)\n",
    "In this part you will learn more about [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and use it to train a classifier and tune its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58925924",
   "metadata": {},
   "source": [
    "#### QB.1 (5 points)\n",
    "For measuring the _accuracy_ of your models, choose a subset of the given dataset as your validation set (Check out [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "## Split the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "## Set your own hyperparameters below, such as:\n",
    "dt_hyperparams = {\n",
    "    'min_samples_split': 2,\n",
    "    'criterion': 'entropy'\n",
    "    # ...\n",
    "}\n",
    "\n",
    "## Train the model and check its performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe85fdf",
   "metadata": {},
   "source": [
    "#### QB.2 (5 points)\n",
    "Take a look at customizable and potentially useful input params of the model, define a range for each of their values, and use GridSearch (Feel free to implement/[import](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) it) and find a set of hyperparametetrs that work best among your candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bc161",
   "metadata": {},
   "source": [
    "#### QB.3 (5 extra points)\n",
    "Visualize the tree splits and interpret it (Hint: Search about `IPython.display.Image`, `pydotplus`, `StringIO`, and `export_graphviz`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a700059dc7a096dd4f4890f5dcc2f87ca5e905804ecea300fbcc0e677f37371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
